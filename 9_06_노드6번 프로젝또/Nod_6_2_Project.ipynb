{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLLswxOrzxchxx/jvVuoTK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noruzzang/AIFFEL_QUEST_cr/blob/master/Nod_6_2_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mc9hhd_TdEj",
        "outputId": "7fe7f6ed-0b2e-4905-b2fd-33670864b090"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdlnU7gUS1et",
        "outputId": "a021dc16-c967-4cb7-9390-7b176d0b2ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Names: ['class_0' 'class_1' 'class_2']\n",
            "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
            "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
            "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
            "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
            "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
            "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
            "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
            "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
            "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
            "\n",
            "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
            "count     178.000000  178.000000            178.000000       178.000000   \n",
            "mean        2.295112    2.029270              0.361854         1.590899   \n",
            "std         0.625851    0.998859              0.124453         0.572359   \n",
            "min         0.980000    0.340000              0.130000         0.410000   \n",
            "25%         1.742500    1.205000              0.270000         1.250000   \n",
            "50%         2.355000    2.135000              0.340000         1.555000   \n",
            "75%         2.800000    2.875000              0.437500         1.950000   \n",
            "max         3.880000    5.080000              0.660000         3.580000   \n",
            "\n",
            "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
            "count       178.000000  178.000000                    178.000000   178.000000  \n",
            "mean          5.058090    0.957449                      2.611685   746.893258  \n",
            "std           2.318286    0.228572                      0.709990   314.907474  \n",
            "min           1.280000    0.480000                      1.270000   278.000000  \n",
            "25%           3.220000    0.782500                      1.937500   500.500000  \n",
            "50%           4.690000    0.965000                      2.780000   673.500000  \n",
            "75%           6.200000    1.120000                      3.170000   985.000000  \n",
            "max          13.000000    1.710000                      4.000000  1680.000000  \n",
            "X_train shape: (142, 13)\n",
            "X_test shape: (36, 13)\n",
            "y_train shape: (142,)\n",
            "y_test shape: (36,)\n",
            "Decision Tree Accuracy: 0.7777777777777778\n",
            "Decision Tree Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       0.86      0.75      0.80        16\n",
            "     class_1       0.50      0.62      0.56         8\n",
            "     class_2       0.92      0.92      0.92        12\n",
            "\n",
            "    accuracy                           0.78        36\n",
            "   macro avg       0.76      0.76      0.76        36\n",
            "weighted avg       0.80      0.78      0.78        36\n",
            "\n",
            "Random Forest Accuracy: 0.9444444444444444\n",
            "Random Forest Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       0.94      0.94      0.94        16\n",
            "     class_1       0.88      0.88      0.88         8\n",
            "     class_2       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.94      0.94      0.94        36\n",
            "weighted avg       0.94      0.94      0.94        36\n",
            "\n",
            "SVM Accuracy: 0.9722222222222222\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       1.00      0.94      0.97        16\n",
            "     class_1       0.89      1.00      0.94         8\n",
            "     class_2       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           0.97        36\n",
            "   macro avg       0.96      0.98      0.97        36\n",
            "weighted avg       0.98      0.97      0.97        36\n",
            "\n",
            "SGD Classifier Accuracy: 0.9444444444444444\n",
            "SGD Classifier Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       1.00      0.88      0.93        16\n",
            "     class_1       0.80      1.00      0.89         8\n",
            "     class_2       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           0.94        36\n",
            "   macro avg       0.93      0.96      0.94        36\n",
            "weighted avg       0.96      0.94      0.95        36\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''필요한 모듈 import하기'''\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler # Make sure you have imported StandardScaler\n",
        "from sklearn.datasets import load_wine\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "'''데이터 준비'''\n",
        "\n",
        "wine = load_wine()  # load_wine 메서드를 사용합니다.\n",
        "\n",
        "'''데이터 이해하기'''\n",
        "\n",
        "X = wine.data  # Feature Data 지정하기\n",
        "y = wine.target  # Label 데이터 지정하기\n",
        "target_names = wine.target_names\n",
        "print(\"Target Names:\", target_names) # Target Names 출력하기\n",
        "\n",
        "df = pd.DataFrame(X, columns=wine.feature_names)\n",
        "description = df.describe()  # 데이터 Describe 해 보기\n",
        "print(description)\n",
        "\n",
        "'''모델 학습과 테스트용 문제지와 정답지를 준비해 봅시다.'''\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "'''데이터 스케일링'''\n",
        "scaler = StandardScaler() # Create a StandardScaler object\n",
        "X_train_scaled = scaler.fit_transform(X_train) # Fit and transform the training data\n",
        "X_test_scaled = scaler.transform(X_test) # Transform the test data\n",
        "\n",
        "'''다양한 모델로 학습시켜보기'''\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "\n",
        "# Decision Tree\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
        "print(\"Decision Tree Classification Report:\\n\", classification_report(y_test, y_pred_dt, target_names=target_names))\n",
        "\n",
        "# Random Forest\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf, target_names=target_names))\n",
        "\n",
        "# SVM\n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "y_pred_svm = svm.predict(X_test_scaled)\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm, target_names=target_names))\n",
        "\n",
        "# SGD Classifier\n",
        "\n",
        "sgd = SGDClassifier()\n",
        "sgd.fit(X_train_scaled, y_train)\n",
        "y_pred_sgd = sgd.predict(X_test_scaled)\n",
        "print(\"SGD Classifier Accuracy:\", accuracy_score(y_test, y_pred_sgd))\n",
        "print(\"SGD Classifier Classification Report:\\n\", classification_report(y_test, y_pred_sgd, target_names=target_names))\n",
        "\n",
        "# Logistic Regression\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000)  # max_iter를 늘려서 수렴 문제를 방지\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = lr.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target Names: ['class_0' 'class_1' 'class_2']\n",
        "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
        "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
        "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
        "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
        "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
        "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
        "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
        "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
        "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
        "\n",
        "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
        "count     178.000000  178.000000            178.000000       178.000000   \n",
        "mean        2.295112    2.029270              0.361854         1.590899   \n",
        "std         0.625851    0.998859              0.124453         0.572359   \n",
        "min         0.980000    0.340000              0.130000         0.410000   \n",
        "25%         1.742500    1.205000              0.270000         1.250000   \n",
        "50%         2.355000    2.135000              0.340000         1.555000   \n",
        "75%         2.800000    2.875000              0.437500         1.950000   \n",
        "max         3.880000    5.080000              0.660000         3.580000   \n",
        "\n",
        "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
        "count       178.000000  178.000000                    178.000000   178.000000  \n",
        "mean          5.058090    0.957449                      2.611685   746.893258  \n",
        "std           2.318286    0.228572                      0.709990   314.907474  \n",
        "min           1.280000    0.480000                      1.270000   278.000000  \n",
        "25%           3.220000    0.782500                      1.937500   500.500000  \n",
        "50%           4.690000    0.965000                      2.780000   673.500000  \n",
        "75%           6.200000    1.120000                      3.170000   985.000000  \n",
        "max          13.000000    1.710000                      4.000000  1680.000000  \n",
        "X_train shape: (142, 13)\n",
        "X_test shape: (36, 13)\n",
        "y_train shape: (142,)\n",
        "y_test shape: (36,)\n",
        "Decision Tree Accuracy: 0.7777777777777778\n",
        "Decision Tree Classification Report:\n",
        "               precision    recall  f1-score   support\n",
        "\n",
        "     class_0       0.86      0.75      0.80        16\n",
        "     class_1       0.50      0.62      0.56         8\n",
        "     class_2       0.92      0.92      0.92        12\n",
        "\n",
        "    accuracy                           0.78        36\n",
        "   macro avg       0.76      0.76      0.76        36\n",
        "weighted avg       0.80      0.78      0.78        36\n",
        "\n",
        "Random Forest Accuracy: 0.9444444444444444\n",
        "Random Forest Classification Report:\n",
        "               precision    recall  f1-score   support\n",
        "\n",
        "     class_0       0.94      0.94      0.94        16\n",
        "     class_1       0.88      0.88      0.88         8\n",
        "     class_2       1.00      1.00      1.00        12\n",
        "\n",
        "    accuracy                           0.94        36\n",
        "   macro avg       0.94      0.94      0.94        36\n",
        "weighted avg       0.94      0.94      0.94        36\n",
        "\n",
        "SVM Accuracy: 0.9722222222222222\n",
        "SVM Classification Report:\n",
        "               precision    recall  f1-score   support\n",
        "\n",
        "     class_0       1.00      0.94      0.97        16\n",
        "     class_1       0.89      1.00      0.94         8\n",
        "     class_2       1.00      1.00      1.00        12\n",
        "\n",
        "    accuracy                           0.97        36\n",
        "   macro avg       0.96      0.98      0.97        36\n",
        "weighted avg       0.98      0.97      0.97        36\n",
        "\n",
        "SGD Classifier Accuracy: 0.9444444444444444\n",
        "SGD Classifier Classification Report:\n",
        "               precision    recall  f1-score   support\n",
        "\n",
        "     class_0       1.00      0.88      0.93        16\n",
        "     class_1       0.80      1.00      0.89         8\n",
        "     class_2       1.00      1.00      1.00        12\n",
        "\n",
        "    accuracy                           0.94        36\n",
        "   macro avg       0.93      0.96      0.94        36\n",
        "weighted avg       0.96      0.94      0.95        36    \n",
        "\n",
        "###학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요? 모델의 성능을 평가하는 지표로는 무엇이 좋을까요? sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요. 선택하신 이유도 설명해 주세요.  \n",
        "Decision Tree Accuracy: 0.7777777777777778\n",
        "\n",
        "\n",
        "Random Forest Accuracy: 0.9444444444444444\n",
        "\n",
        "\n",
        "SVM Accuracy: 0.9722222222222222\n",
        "\n",
        "\n",
        "SGD Classifier Accuracy: 0.9444444444444444\n",
        "\n",
        "가장 높은 수치인 SVM Accuracy를 선택하겠습니다\n",
        "\n"
      ],
      "metadata": {
        "id": "Jk3DQwu8VXqv"
      }
    }
  ]
}
